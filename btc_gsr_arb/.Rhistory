theoretical_prob <- dbinom(50, size = 100, prob = 0.5)
print(theoretical_prob)
simulated_prob <- mean(results == 50)
print(simulated_prob)
#1
results <- rbinom(n = 1000, size = 100, prob = 0.5)
#2
mean_heads <- mean(results)
print(mean_heads)
#3
hist(results, breaks = 30, probability = TRUE,
main = "Histogram of Simulated Results vs Theoretical PMF",
xlab = "Number of Heads", col = "blue")
x_values <- 0:100
pmf <- dbinom(x_values, size = 100, prob = 0.5)
points(x_values, pmf, col = "green", type = "b", pch = 19)
#4
theoretical_prob <- dbinom(50, size = 100, prob = 0.5)
print(theoretical_prob)
simulated_prob <- mean(results == 50)
print(simulated_prob)
#1
results <- rbinom(n = 1000, size = 100, prob = 0.5)
#2
mean_heads <- mean(results)
print(mean_heads)
#3
hist(results, breaks = 30, probability = TRUE,
main = "Histogram of Simulated Results vs Theoretical PMF",
xlab = "Number of Heads", col = "gray")
x_values <- 0:100
pmf <- dbinom(x_values, size = 100, prob = 0.5)
points(x_values, pmf, col = "green", type = "b", pch = 19)
#4
theoretical_prob <- dbinom(50, size = 100, prob = 0.5)
print(theoretical_prob)
simulated_prob <- mean(results == 50)
print(simulated_prob)
#Next Exercise
#1
results2 <- rpois(1000, 30)
#2
theo_prob <- 1 - ppois(1000, 35)
simulated <- mean(results2)
print(theo_prob)
print(simulated)
#3
hist(results2, breaks = 30, probability = TRUE,
main = "Poisson Distribution: Simulated vs Theoretical",
xlab = "Number of Customers", col = "gray")
x_values <- 0:max(customers)
#Next Exercise
#1
results2 <- rpois(1000, 30)
#2
theo_prob <- 1 - ppois(1000, 35)
simulated <- mean(results2)
print(theo_prob)
print(simulated)
#3
hist(results2, breaks = 30, probability = TRUE,
main = "Poisson Distribution: Simulated vs Theoretical",
xlab = "Number of Customers", col = "gray")
x_values <- 0:max(customers)
#Next Exercise
#1
results2 <- rpois(1000, 30)
#2
theo_prob <- 1 - ppois(1000, 35)
simulated <- mean(results2)
print(theo_prob)
print(simulated)
#3
hist(results2, breaks = 30, probability = TRUE,
main = "Poisson Distribution: Simulated vs Theoretical",
xlab = "Number of Customers", col = "gray")
x_values <- 0:max(customers)
#Next Exercise
#1
results2 <- rpois(1000, 30)
#2
theo_prob <- 1 - ppois(1000, 35)
simulated <- mean(results2)
print(theo_prob)
print(simulated)
#3
hist(results2, breaks = 30, probability = TRUE,
main = "Poisson Distribution: Simulated vs Theoretical",
xlab = "Number of Customers", col = "gray")
x_values <- 0:max(customers)
#Next Exercise
#1
results2 <- rpois(1000, 30)
#2
theo_prob <- 1 - ppois(1000, 35)
simulated <- mean(results2)
print(theo_prob)
print(simulated)
#3
hist(results2, breaks = 30, probability = TRUE,
main = "Poisson Distribution: Simulated vs Theoretical",
xlab = "Number of Customers", col = "gray")
x_values <- 0:max(results2)
pmf <- dpois(x_values, lambda = 30)
points(x_values, pmf, col = "lightgreen", type = "b", pch = 19)
#Excercise 3
#1
set.seed(123)
heights <- rnorm(n = 1000, mean = 175, sd = 7)
#2
theoretical_prob <- 1 - pnorm(185, mean = 175, sd = 7)
print(theoretical_prob)
simulated_prob <- mean(heights > 185)
print(simulated_prob)
#3
qqnorm(heights, main = "Q-Q Plot of Simulated Heights")
qqline(heights, col = "red", lwd = 2)
#4
sample_mean <- mean(heights)
sample_sd <- sd(heights)
n <- length(heights)
t_critical <- qt(0.975, df = n - 1)
margin_of_error <- t_critical * (sample_sd / sqrt(n))
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
print(c(lower_bound, upper_bound))
#Excercise 3
#1
set.seed(123)
heights <- rnorm(n = 1000, mean = 175, sd = 7)
#2
theoretical_prob <- 1 - pnorm(185, mean = 175, sd = 7)
print(theoretical_prob)
simulated_prob <- mean(heights > 185)
print(simulated_prob)
#3
qqnorm(heights, main = "Q-Q Plot of Simulated Heights")
qqline(heights, col = "green", lwd = 2)
#4
sample_mean <- mean(heights)
sample_sd <- sd(heights)
n <- length(heights)
t_critical <- qt(0.975, df = n - 1)
margin_of_error <- t_critical * (sample_sd / sqrt(n))
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
print(c(lower_bound, upper_bound))
#Excercise 3
#1
set.seed(123)
heights <- rnorm(n = 1000, mean = 175, sd = 7)
#2
theoretical_prob <- 1 - pnorm(185, mean = 175, sd = 7)
print(theoretical_prob)
simulated_prob <- mean(heights > 185)
print(simulated_prob)
#3
qqnorm(heights, main = "Q-Q Plot of Simulated Heights")
qqline(heights, col = "lightgreen", lwd = 2)
#4
sample_mean <- mean(heights)
sample_sd <- sd(heights)
n <- length(heights)
t_critical <- qt(0.975, df = n - 1)
margin_of_error <- t_critical * (sample_sd / sqrt(n))
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
print(c(lower_bound, upper_bound))
data(mtcars)
#mean
mean_mpg <- mean(mtcars$mpg)
mean_mpg
data(mtcars)
#mean
mean_mpg <- mean(mtcars$mpg)
mean_mpg
#SEM
sem_mpg <- sd(mtcars$mpg) / sqrt(nrow(mtcars))
sem_mpg
#tscore
df <- nrow(mtcars) - 1
t_score <- qt(0.975, df)  # two-tailed 95% CI
t_score
data(mtcars)
#mean
mean_mpg <- mean(mtcars$mpg)
mean_mpg
#SEM
sem_mpg <- sd(mtcars$mpg) / sqrt(nrow(mtcars))
sem_mpg
#tscore
df <- nrow(mtcars) - 1
t_score <- qt(0.975, df)  # two-tailed 95% CI
t_score
#MoE
margin_error <- t_score * sem_mpg
margin_error
data(mtcars)
#hist
hist(mtcars$mpg, main = "Distribution of Miles Per Gallon")
#mean
mean_mpg <- mean(mtcars$mpg)
mean_mpg
#SEM
sem_mpg <- sd(mtcars$mpg) / sqrt(nrow(mtcars))
sem_mpg
#tscore
df <- nrow(mtcars) - 1
t_score <- qt(0.975, df)  # two-tailed 95% CI
t_score
#MoE
margin_error <- t_score * sem_mpg
margin_error
data(mtcars)
#hist
hist(mtcars$mpg, main = "Distribution of Miles Per Gallon")
#mean
mean_mpg <- mean(mtcars$mpg)
mean_mpg
#SEM
sem_mpg <- sd(mtcars$mpg) / sqrt(nrow(mtcars))
sem_mpg
#tscore
df <- nrow(mtcars) - 1
t_score <- qt(0.975, df)  # two-tailed 95% CI
t_score
#MoE
margin_error <- t_score * sem_mpg
margin_error
#CI
lower_bound <- mean_mpg - margin_error
upper_bound <- mean_mpg + margin_error
c(lower_bound, upper_bound)
#CI
t.test(mtcars$mpg)$conf.int
#CI
ci <- t.test(mtcars$mpg)$conf.int
lower_bound <- ci[1]
upper_bound <- ci[2]
ci <- t.test(mtcars$mpg)$conf.int
lower_bound <- ci[1]
upper_bound <- ci[2]
print(lower_bound, upper_bound)
ci <- t.test(mtcars$mpg)$conf.int
print(ci[1],ci[2])
print(ci[1], ci[2])
ci <- t.test(mtcars$mpg)$conf.int
print(ci[1])
print(ci[2])
boxplot(mtcars$mpg, main = "MPG Distribution")
t.test(mtcars$mpg, mu = 20)
t.test(mtcars$mpg, mu = 20, alternative = "greater")
t.test(mtcars$mpg, mu = 20)
#One-Sided Test (Greater) at 95% Confidence Level:
t.test(mtcars$mpg, mu = 20, alternative = "greater")
# Interpretation: p-value < 0.05 suggests mean is greater than 20
t.test(mtcars$mpg, mu = 20, alternative = "less")
#Interpretation: p-value < 0.05 suggests mean is less than 20
One-Sided Test (Less) at 95% Confidence Level
#One-Sided Test (Less) at 95% Confidence Level
t.test(mtcars$mpg, mu = 20, alternative = "less")
#Interpretation: p-value < 0.05 suggests mean is less than 20
t.test(mtcars$mpg, mu = 20, conf.level = 0.99)
boxplot(extra ~ group, data = sleep, main = "Sleep Increase by Drug Type")
boxplot(extra ~ group, data = sleep, main = "Sleep Increase by Drug Type")
#Two-Sample t-Test
data(sleep)
#Data Viz
boxplot(extra ~ group, data = sleep, main = "Sleep Increase by Drug Type")
#Two-Sample t-Test
data(sleep)
#Data Viz
boxplot(extra ~ group, data, main = "Sleep Increase by Drug Type")
data(mtcars)
data(mtcars)
#1 Confidence Intervals
#hist
hist(mtcars$mpg, main = "Distribution of Miles Per Gallon")
#Two-Sample t-Test
data(sleep)
#Data Viz
boxplot(extra ~ group, data, main = "Sleep Increase by Drug Type")
data(sleep)
head(sleep)
boxplot(extra ~ group, data, main = "Sleep Increase by Drug Type")
boxplot(extra ~ group, data, main = "Sleep Increase by Drug Type")
boxplot(extra ~ group, data = sleep, main = "Sleep Increase by Drug Type")
#Independent Samples
t.test(extra ~ group, data = sleep, paired = FALSE, var.equal = TRUE)
t.test(sleep$extra[sleep$group == 1],
sleep$extra[sleep$group == 2],
paired = TRUE)
t.test(extra ~ group, data = sleep, paired = FALSE, var.equal = TRUE)
t.test(sleep$extra[sleep$group == 2],
sleep$extra[sleep$group == 1],
paired = TRUE,
alternative = "greater")
#Independent Samples
t.test(extra ~ group, data = sleep, paired = FALSE, var.equal = TRUE)
#Paired Samples
t.test(sleep$extra[sleep$group == 1],
sleep$extra[sleep$group == 2],
paired = TRUE)
t.test(mtcars$mpg, mu = 20, conf.level = 0.99)
#Paired Samples
t.test(sleep$extra[sleep$group == 1],
sleep$extra[sleep$group == 2],
paired = TRUE)
mosaicplot(table(mtcars$cyl, mtcars$am), main = "Cylinders vs Transmission")
# Create contingency table
contingency_table <- table(mtcars$cyl, mtcars$am)
# Perform chi-squared test
chi_sq_test <- chisq.test(contingency_table)
chisq.test(contingency_table)
#ANOVA Test
boxplot(mpg ~ cyl, data = mtcars, main = "MPG by Number of Cylinders")
# Convert cyl to factor
mtcars$cyl <- as.factor(mtcars$cyl)
# Perform one-way ANOVA
anova_result <- aov(mpg ~ cyl, data = mtcars)
# Examine ANOVA table
summary(anova_result)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
t.test(extra ~ group, data = sleep, paired = FALSE, var.equal = TRUE)
t.test(sleep$extra[sleep$group == 1],
sleep$extra[sleep$group == 2],
paired = TRUE)
chisq.test(contingency_table)
#ANOVA Test
boxplot(mpg ~ cyl, data = mtcars, main = "MPG by Number of Cylinders")
# Convert cyl to factor
mtcars$cyl <- as.factor(mtcars$cyl)
# Perform one-way ANOVA
anova_result <- aov(mpg ~ cyl, data = mtcars)
# Examine ANOVA table
summary(anova_result)
anova_result <- aov(mpg ~ cyl, data = mtcars)
summary(anova_result)
#Linear Regression
linear_model <- lm(mpg ~ wt, data = mtcars)
# Examine summary
summary(linear_model)
Linear Regression
#Linear Regression
plot(mpg ~ wt, data = mtcars, main = "MPG vs Weight")
linear_model <- lm(mpg ~ wt, data = mtcars)
# Examine summary
summary(linear_model)
library(ggplot2)
library(dplyr)
library(zoo)
library(tseries)
# === 1. Parameters (tweak anything here) ===
window_size <- 30    # look-back window in days
z_thresh    <- 1     # entry/exit z-score threshold
# === 2. Working Directory ===
setwd("/Users/lucasportela/Documents/Academics/College/Semester_2/Probs_Stats/Stat_arb")  # project folder
# === 3. Helper Function ===
prepare_data <- function(path) {
read.csv(path, stringsAsFactors = FALSE) %>%
mutate(
Date   = as.Date(Date),
across(c(Open, High, Low, Close), ~ suppressWarnings(as.numeric(.)))
) %>%
filter(!is.na(Date), !is.na(Close))  # drop incomplete rows
}
# === 4. Load & Prepare Data ===
KROP_data <- prepare_data("KROP.csv")  # first ETF
PBJ_data  <- prepare_data("PBJ.csv")   # second ETF
# === 5. Merge & Initialize ===
aligned <- inner_join(KROP_data, PBJ_data, by = "Date", suffix = c("_KROP","_PBJ")) %>%
arrange(Date) %>%
mutate(
resid_roll     = NA_real_,  # today's spread/residual
alpha_roll     = NA_real_,  # intercept from hedge regression
beta_roll      = NA_real_,  # slope from hedge regression
mu_roll        = NA_real_,  # mean of residuals over window
sd_roll        = NA_real_,  # sd of residuals over window
threshold_roll = NA_real_,  # z_thresh * sd
z_roll         = NA_real_,  # z-score of today's residual
signal_roll    = 0,         # raw trade signal (+1, -1, 0)
position_roll  = 0          # position for next day
)
n <- nrow(aligned)
# === 6. Rolling Estimation & Signal Generation ===
for (i in (window_size + 1):(n - 1)) {
calib <- aligned[(i - window_size):(i - 1), ]  # calibration window
# 6.1 Fit linear regression: PBJ_t ~ alpha + beta * KROP_t
mod <- lm(Close_PBJ ~ Close_KROP, data = calib)
a   <- coef(mod)[1]; b <- coef(mod)[2]
aligned$alpha_roll[i] <- a
aligned$beta_roll[i]  <- b
# 6.2 Compute residual stats on calibration window
resid_calib <- calib$Close_PBJ - (a + b * calib$Close_KROP)
mu <- mean(resid_calib); s <- sd(resid_calib)
aligned$mu_roll[i]        <- mu
aligned$sd_roll[i]        <- s
aligned$threshold_roll[i] <- z_thresh * s
# 6.3 Today's residual & z-score
today_resid          <- aligned$Close_PBJ[i] - (a + b * aligned$Close_KROP[i])
aligned$resid_roll[i] <- today_resid
aligned$z_roll[i]     <- (today_resid - mu) / s
# 6.4 Trade signal: +1 = go long PBJ, -1 = go short PBJ
sig <- ifelse(aligned$z_roll[i] < -z_thresh,  1,
ifelse(aligned$z_roll[i] >  z_thresh, -1, 0))
aligned$signal_roll[i]     <- sig
aligned$position_roll[i + 1] <- sig  # position enters next day
}
# === 7. Compute PnL & Track Positions ===
aligned <- aligned %>%
mutate(
pnl_roll    = ifelse(row_number() > 1,
position_roll * (resid_roll - lag(resid_roll)),
0),           # daily PnL
pnl_roll    = ifelse(is.na(pnl_roll), 0, pnl_roll),
cumPnL_roll = cumsum(pnl_roll)      # cumulative PnL
) %>%
mutate(
prev_pos   = lag(position_roll, default = 0),             # yesterday's position
entry_roll = prev_pos == 0 & position_roll != 0,          # mark entries
exit_roll  = prev_pos != 0 & position_roll == 0          # mark exits
)
# === 8. Statistical Tests ===
adf_roll <- adf.test(na.omit(aligned$resid_roll[(window_size + 1):n]))
print(adf_roll)  # test residual stationarity
pnl_test <- aligned$pnl_roll[(window_size + 2):n]  # drop initial zeros
tt_roll  <- t.test(pnl_test, mu = 0, alternative = "greater")
print(tt_roll)    # test positive mean PnL
# === 9. Plotting Results ===
# 9.1 Cumulative PnL
ggplot(aligned, aes(Date, cumPnL_roll)) +
geom_line(size = 1) +
labs(
title    = sprintf("Cumulative PnL: %d-Day Rolling Z-Score", window_size),
subtitle = sprintf("Threshold = ±%.2f σ", z_thresh),
x        = "Date", y = "Cumulative PnL"
) +
theme_minimal()
# 9.2 PBJ vs Hedge Line + markers
aligned <- aligned %>% mutate(hedgeLine_roll = alpha_roll + beta_roll * Close_KROP)
ggplot(aligned, aes(Date)) +
geom_line(aes(y = Close_PBJ), size = 1) +      # actual PBJ price
geom_line(aes(y = hedgeLine_roll), linetype = "dashed", size = 1) +  # fitted hedge
geom_point(data = filter(aligned, entry_roll), aes(y = Close_PBJ), shape = 24, size = 2) +  # ▲ entry
geom_point(data = filter(aligned, exit_roll),  aes(y = Close_PBJ), shape = 25, size = 2) +  # ▼ exit
labs(
title    = sprintf("PBJ vs %d-Day Rolling Hedge Line", window_size),
subtitle = "▲ entries, ▼ exits",
x        = "Date", y = "Price"
) +
theme_minimal()
# === 10. Scale PnL & Report Final Results ===
position_size <- 10000   # $10k per trade
portfolio     <- 1e6     # $1M total capital
aligned <- aligned %>%
mutate(
# scaled daily PnL (handle initial NA residuals)
pnl_roll    = ifelse(row_number() > 1,
position_roll * (resid_roll - lag(resid_roll)) * position_size,
0),
pnl_roll    = ifelse(is.na(pnl_roll), 0, pnl_roll),  # replace NA with 0
cumPnL_roll = cumsum(pnl_roll)        # scaled cumulative PnL
)
# Final metrics
final_profit <- tail(aligned$cumPnL_roll, 1)
return_pct   <- final_profit / portfolio * 100
message(sprintf("Total Profit = $%.2f", final_profit))
message(sprintf("Return       = %.2f%%", return_pct))
source("~/.active-rstudio-document")
library(ggplot2)
library(dplyr)
library(zoo)
library(tseries)
# === 1. Parameters (tweak anything here) ===
window_size <- 90    # look‐back window in days
z_thresh    <- 2.0   # entry/exit z‐score threshold
# === 2. Working Directory ===
setwd("/Users/lucasportela/Documents/btc_arb")
library(ggplot2)
library(dplyr)
library(zoo)
library(tseries)
# === 1. Parameters (tweak anything here) ===
window_size <- 90    # look‐back window in days
z_thresh    <- 2.0   # entry/exit z‐score threshold
# === 2. Working Directory ===
setwd("/Users/lucasportela/Documents/bitcoin_arb")
# === 3. Load & Prepare Aligned BTC–GSR Data ===
aligned <- read.csv("Aligned_BTC_GSR.csv", stringsAsFactors = FALSE) %>%
mutate(
Date        = as.Date(Date),
Close_BTC   = as.numeric(Close),
GSR         = as.numeric(GSR),
# compute log‐return for BTC
r_btc       = c(NA, diff(log(Close_BTC))),
# compute pct‐change for GSR
d_gsr       = c(NA, diff(GSR) / lag(GSR))
) %>%
arrange(Date) %>%
filter(!is.na(r_btc), !is.na(d_gsr)) %>%
mutate(
resid_roll     = NA_real_,
alpha_roll     = NA_real_,
beta_roll      = NA_real_,
mu_roll        = NA_real_,
sd_roll        = NA_real_,
threshold_roll = NA_real_,
z_roll         = NA_real_,
signal_roll    = 0,
position_roll  = 0
)
